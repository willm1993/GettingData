{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ♦ Grabbing static text files with `Pandas`\n",
    "While once much more common, a number of agencies still provide access to data as raw text files served up on a web server. Some examples are [USGS Water Use Data](https://water.usgs.gov/watuse/data/2010/index.html), and [NWIS Stream Flow data](https://waterdata.usgs.gov/nc/nwis/water_use?format=rdb&rdb_compression=value&wu_area=County&wu_year=ALL&wu_county=ALL&wu_category=IN&wu_county_nms=--ALL%2BCounties--&wu_category_nms=Industrial). If you've ever used these data in your projects, you know it's fairly easy to manage: just download the link to the file (if a download link is provided), or justcopy and paste. \n",
    "\n",
    "But if you have a lot of files to download, or if, like the stream gage data, you need to download it in real-time for your reseach, you can write a script to do this. Turns out it's note even that hard, thanks to the `pandas` package. \n",
    "\n",
    "This notebook demonstrates how `pandas` can read a text file from the web just as easily as a text file located on our local machine. We just substitute the data's web address (i.e., its URL) where we'd put the filename in using the `read_csv` function. It's that easy, but it only works if the data being served remotely is a raw text file...\n",
    "\n",
    "Here we examine the process for grabbing 2010 water use data for North Carolina hosted on a USGS server..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, for argument's sake, let's see how this data set would be nabbed manually:\n",
    "* Navigate to https://waterdata.usgs.gov/nwis/wu\n",
    "* In the upper-righthand side, select `North Carolina` from the dropdown\n",
    "* Select `State Data`\n",
    "* For retrieval criteria, choose:\n",
    " * Year `--All Years--`\n",
    " * Area Type: `County`, `--All Counties--`\n",
    " * Category: `Industrial`\n",
    "* Hit `Submit`\n",
    "* For Output Format, select `Tab-separated data` and `Display in Browser`\n",
    "* When the data appear, the URL in the browser is what we want; it will always link to these data, and we can use pandas to pull the data we want using that URL.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas module\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the url as a variable; this is the URL we generated above\n",
    "theURL = 'https://waterdata.usgs.gov/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&period=1&begin_date=&end_date=&site_no=02085070'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tz_cd</th>\n",
       "      <th>89062_00060</th>\n",
       "      <th>89062_00060_cd</th>\n",
       "      <th>89063_00065</th>\n",
       "      <th>89063_00065_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5s</td>\n",
       "      <td>15s</td>\n",
       "      <td>20d</td>\n",
       "      <td>6s</td>\n",
       "      <td>14n</td>\n",
       "      <td>10s</td>\n",
       "      <td>14n</td>\n",
       "      <td>10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>59.5</td>\n",
       "      <td>P</td>\n",
       "      <td>1.87</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:15</td>\n",
       "      <td>EST</td>\n",
       "      <td>59.5</td>\n",
       "      <td>P</td>\n",
       "      <td>1.87</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:30</td>\n",
       "      <td>EST</td>\n",
       "      <td>60.8</td>\n",
       "      <td>P</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:45</td>\n",
       "      <td>EST</td>\n",
       "      <td>60.8</td>\n",
       "      <td>P</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_cd   site_no          datetime tz_cd 89062_00060 89062_00060_cd  \\\n",
       "0        5s       15s               20d    6s         14n            10s   \n",
       "1      USGS  02085070  2018-11-05 00:00   EST        59.5              P   \n",
       "2      USGS  02085070  2018-11-05 00:15   EST        59.5              P   \n",
       "3      USGS  02085070  2018-11-05 00:30   EST        60.8              P   \n",
       "4      USGS  02085070  2018-11-05 00:45   EST        60.8              P   \n",
       "\n",
       "  89063_00065 89063_00065_cd  \n",
       "0         14n            10s  \n",
       "1        1.87              P  \n",
       "2        1.87              P  \n",
       "3        1.88              P  \n",
       "4        1.88              P  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data as a pandas data frame and display the first 5 rows\n",
    "# -Note we need to specify that it's a tab delimited file and uses '#' to indicated commments\n",
    "dfNWIS = pd.read_csv(theURL, delimiter='\\t', comment='#')\n",
    "dfNWIS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's one catch: the second line of the dataframe is not the data we want, but rather a listing of the field type and width. Pandas offers two ways around this. First, we could just drop the first row..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tz_cd</th>\n",
       "      <th>89062_00060</th>\n",
       "      <th>89062_00060_cd</th>\n",
       "      <th>89063_00065</th>\n",
       "      <th>89063_00065_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>59.5</td>\n",
       "      <td>P</td>\n",
       "      <td>1.87</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:15</td>\n",
       "      <td>EST</td>\n",
       "      <td>59.5</td>\n",
       "      <td>P</td>\n",
       "      <td>1.87</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:30</td>\n",
       "      <td>EST</td>\n",
       "      <td>60.8</td>\n",
       "      <td>P</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 00:45</td>\n",
       "      <td>EST</td>\n",
       "      <td>60.8</td>\n",
       "      <td>P</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USGS</td>\n",
       "      <td>02085070</td>\n",
       "      <td>2018-11-05 01:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>60.8</td>\n",
       "      <td>P</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_cd   site_no          datetime tz_cd 89062_00060 89062_00060_cd  \\\n",
       "1      USGS  02085070  2018-11-05 00:00   EST        59.5              P   \n",
       "2      USGS  02085070  2018-11-05 00:15   EST        59.5              P   \n",
       "3      USGS  02085070  2018-11-05 00:30   EST        60.8              P   \n",
       "4      USGS  02085070  2018-11-05 00:45   EST        60.8              P   \n",
       "5      USGS  02085070  2018-11-05 01:00   EST        60.8              P   \n",
       "\n",
       "  89063_00065 89063_00065_cd  \n",
       "1        1.87              P  \n",
       "2        1.87              P  \n",
       "3        1.88              P  \n",
       "4        1.88              P  \n",
       "5        1.88              P  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the first row, and again show the first 5 rows of data...\n",
    "dfNWIS.drop(0,axis='rows',inplace=True)\n",
    "dfNWIS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way around this is to invoke the skip rows option when reading the CSV. If you look at the file we are importing, you see that the first 49 rows are comments, then comes our header row, and then the field type row that we don't want. So we want to skip rows 1 thru 49 and also line 51. If we create a list of these row numbers, we can pass that to the skip_rows parameter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of numbers 0 thru 26, recalling Python lists are zero-indexed...\n",
    "rowsToSkip = list(range(26))\n",
    "#Append '29' to the list\n",
    "rowsToSkip.append(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tz_cd</th>\n",
       "      <th>89062_00060</th>\n",
       "      <th>89062_00060_cd</th>\n",
       "      <th>89063_00065</th>\n",
       "      <td>89063_00065_cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">USGS</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">02085070</th>\n",
       "      <th>2018-11-05 00:00</th>\n",
       "      <th>EST</th>\n",
       "      <th>59.5</th>\n",
       "      <th>P</th>\n",
       "      <th>1.87</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-05 00:15</th>\n",
       "      <th>EST</th>\n",
       "      <th>59.5</th>\n",
       "      <th>P</th>\n",
       "      <th>1.87</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-05 00:30</th>\n",
       "      <th>EST</th>\n",
       "      <th>60.8</th>\n",
       "      <th>P</th>\n",
       "      <th>1.88</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-05 00:45</th>\n",
       "      <th>EST</th>\n",
       "      <th>60.8</th>\n",
       "      <th>P</th>\n",
       "      <th>1.88</th>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              # \n",
       "agency_cd site_no  datetime         tz_cd 89062_00060 89062_00060_cd 89063_00065  89063_00065_cd\n",
       "USGS      02085070 2018-11-05 00:00 EST   59.5        P              1.87                      P\n",
       "                   2018-11-05 00:15 EST   59.5        P              1.87                      P\n",
       "                   2018-11-05 00:30 EST   60.8        P              1.88                      P\n",
       "                   2018-11-05 00:45 EST   60.8        P              1.88                      P"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the read_csv function as before, but skip the rows we want to skip\n",
    "dfNWIS = pd.read_csv(theURL, delimiter='\\t', skiprows=rowsToSkip)\n",
    "dfNWIS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this as a pandas data frame, we can analyze it here, or we can simply save a copy to our local machine. For the latter, pandas' to_csv() function works quite easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNWIS.to_csv(\"Data/NWISDischarge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Teaser*: We'll look more and Pandas soon, but here we see we can make a quick plot of the data. Here we plot an annual time series of NC Industrial groundwater withdrawals:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-04b6c6c1ce2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m'Industrial self-supplied groundwater withdrawals, fresh, in Mgal/d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdfNWIS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\my_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m   5160\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   5161\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5162\u001b[1;33m                        **kwargs)\n\u001b[0m\u001b[0;32m   5163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5164\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\my_env\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\my_env\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\ESRI\\conda\\envs\\my_env\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, mutated, validate)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2934\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2935\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'year'"
     ]
    }
   ],
   "source": [
    "col =  'Industrial self-supplied groundwater withdrawals, fresh, in Mgal/d'\n",
    "dfNWIS.groupby('year')[col].mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise: \n",
    "► See if you can import NWIS discharge data located at this web address:<br>\n",
    "http://waterdata.usgs.gov/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&period=1&begin_date=&end_date=&site_no=02085070<br> and save it to a file named `NWISDischarge.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas module\n",
    "import pandas as pd\n",
    "\n",
    "# Set the url as a variable; this is the URL we generated above\n",
    "theURL = 'https://waterdata.usgs.gov/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&period=1&begin_date=&end_date=&site_no=02085070'\n",
    "\n",
    "# Read in the data as a pandas data frame and display the first 5 rows\n",
    "# -Note we need to specify that it's a tab delimited file and uses '#' to indicated commments\n",
    "dfNWIS = pd.read_csv(theURL, delimiter='\\t', comment='#')\n",
    "dfNWIS.head()\n",
    "\n",
    "#Drop the first row, and again show the first 5 rows of data...\n",
    "dfNWIS.drop(0,axis='rows',inplace=True)\n",
    "dfNWIS.head()\n",
    "\n",
    "dfNWIS.to_csv(\"Data/NWISDischarge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
